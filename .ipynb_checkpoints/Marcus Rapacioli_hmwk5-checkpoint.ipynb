{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cb4fdf7b",
   "metadata": {},
   "source": [
    "Hmwk 4. Built on max's code and my first 3 homeworks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df28dadb",
   "metadata": {},
   "source": [
    "Process:\n",
    "1. I used the below code to collect training data for 10 hours and saved it as cvs files  in this directory under the folder `training_data`. The `training_data_old` directory has a further 10 hours of data but does not include USDAUD as I collected it prior to the in-class clarification about this currency pair.\n",
    "2. The first section of the code imports and prepares the data to be used in the regression models\n",
    "3. Instead of looping over all the currency pairs, I run the regression process (adapted from the pycaret tutorial found in their docs) for each currency pair separately. This was in order to select the best model which varied from one pair to the next.\n",
    "4. After setting up the models, I tuned, finalised and saved them as per the docs instructions. I then load the models back into the application to be used in the main function.\n",
    "5. In the main function, every 6 minutes I loop over the currency pairs and replace the vol and fd values with a classificaiton based on the training data. In order to do this I compared the real-time values to the traning data and programmatically added a class based on whether there it was a high, medium or low value.\n",
    "6. I then use this real-time data each six minutes to make a prediction for the next six minutes, compare it to the actual return and keep note of the error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1e05db0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import datetime\n",
    "import time\n",
    "from polygon import RESTClient\n",
    "from sqlalchemy import create_engine \n",
    "from sqlalchemy import text\n",
    "import pandas as pd\n",
    "from math import sqrt\n",
    "from math import isnan\n",
    "import matplotlib.pyplot as plt\n",
    "from numpy import mean\n",
    "from numpy import std\n",
    "from math import floor\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e4c63450",
   "metadata": {},
   "outputs": [],
   "source": [
    "#-------Hmwk4----------\n",
    "# A dictionary defining the set of currency pairs we will be pulling data for\n",
    "currency_pairs = [[\"EUR\",\"USD\",],\n",
    "                  [\"GBP\",\"USD\",],\n",
    "                  [\"USD\",\"CHF\",],\n",
    "                  [\"USD\",\"CAD\",],\n",
    "                  [\"USD\",\"HKD\",],\n",
    "                  [\"USD\",\"AUD\",],\n",
    "                  [\"USD\",\"NZD\",],\n",
    "                  [\"USD\",\"SGD\",]]\n",
    "\n",
    "\n",
    "# Do the necessary imports\n",
    "\n",
    "import pandas as pd\n",
    "from pycaret.regression import *\n",
    "\n",
    "#Create dictionaries to house our raw data, prepared data, models, predictions\n",
    "dfs = {}\n",
    "dfs2 ={}\n",
    "prepared = {}\n",
    "models = {}\n",
    "predictions = {}\n",
    "\n",
    "# Create dictionaries that hold volatility and fd data, we will use these in the main function to assign a class to vol and fd\n",
    "vol_data = {}\n",
    "fd_data = {}\n",
    "\n",
    "\n",
    "#Import our training data from the training_data directory\n",
    "for currency in currency_pairs:\n",
    "        # Set the input variables to the API\n",
    "        from_ = currency[0]\n",
    "        to = currency[1]\n",
    "        dfs[f'{from_}{to}'] = pd.read_csv(f'training_data/{from_}{to}_ts.csv')\n",
    "        dfs2[f'{from_}{to}'] = pd.read_csv(f'training_data/{from_}{to}_ts.csv')\n",
    "        \n",
    "        \n",
    "        # Remove the time period coloumn as it may skew the prediction\n",
    "        del dfs[f'{from_}{to}']['period']\n",
    "        \n",
    "        # sort the values by volatility and assign them into high, medium and low classifications\n",
    "        dfs[f'{from_}{to}'] = dfs[f'{from_}{to}'].sort_values(by = [\"volatility\"])\n",
    "        dfs[f'{from_}{to}'].reset_index(drop=True, inplace=True)\n",
    "        \n",
    "        # Saved the ordered vol data to classify real time data points\n",
    "        vol_data[f'{from_}{to}'] = dfs2[f'{from_}{to}'].loc[0:100, 'volatility']\n",
    "        \n",
    "        dfs[f'{from_}{to}'].loc[0:32, 'volatility'] = 1\n",
    "        dfs[f'{from_}{to}'].loc[33:66, 'volatility'] = 2\n",
    "        dfs[f'{from_}{to}'].loc[67:100, 'volatility'] = 3\n",
    "        \n",
    "        # repeat the process for fractal dimension\n",
    "        dfs[f'{from_}{to}'] = dfs[f'{from_}{to}'].sort_values(by = [\"fd\"])\n",
    "        dfs[f'{from_}{to}'].reset_index(drop=True, inplace=True)\n",
    "        \n",
    "        # Saved the ordered fd data to classify real time data points\n",
    "        fd_data[f'{from_}{to}'] = dfs2[f'{from_}{to}'].loc[0:100, 'fd']\n",
    "        \n",
    "        dfs[f'{from_}{to}'].loc[0:32, 'fd'] = 1\n",
    "        dfs[f'{from_}{to}'].loc[33:66, 'fd'] = 2\n",
    "        dfs[f'{from_}{to}'].loc[67:100, 'fd'] = 3\n",
    "        \n",
    "        # multiply the return by 100000, this will make it easier to make predictions as otherwise our return values are all very closed to 0.\n",
    "        # we will divide the retrun by 100000 later\n",
    "        \n",
    "        dfs[f'{from_}{to}'].loc[0:100, 'return'] = dfs[f'{from_}{to}'].loc[0:100, 'return'] *100000\n",
    "       \n",
    "    \n",
    "        # Add the prepared data for each currency to the prepared dictionary\n",
    "        prepared[f'{from_}{to}'] = dfs[f'{from_}{to}']\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7507186",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instead of looping over the currency pairs as I do elsewhere in this project, I run each currency pair in a separate model. This was in order to select the best regression model that varied depending on the currency pair.\n",
    "\n",
    "# EURUSD\n",
    "# Below code creates the regresion model, most of it is adapted from the pycaret tutorial\n",
    "\n",
    "        \n",
    "# Set up the regression\n",
    "EURUSD_reg = setup(data = prepared['EURUSD'], target = 'return', session_id=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efb750d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Select the best model\n",
    "EURUSD_best = compare_models(exclude = ['ransac'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ab7a34e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select the best model\n",
    "EURUSD_en = create_model(\"en\")\n",
    "\n",
    "# Tune the rf model\n",
    "EURUSD_tuned_en = tune_model(EURUSD_en)\n",
    "\n",
    "# Finalise the model\n",
    "EURUSD_model = finalize_model(EURUSD_tuned_en)\n",
    "\n",
    "# Save the model\n",
    "save_model(EURUSD_model, 'EURUSD_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28db8c9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# GBPUSD\n",
    "# Below code creates the regresion model, most of it is adapted from the pycaret tutorial\n",
    "\n",
    "        \n",
    "# Set up the regression\n",
    "GBPUSD_reg = setup(data = prepared['GBPUSD'], target = 'return', session_id=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "827ed3f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Select the best model\n",
    "GBPUSD_best = compare_models(exclude = ['ransac'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88bf67fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select the best model\n",
    "GBPUSD_knn = create_model(\"knn\")\n",
    "\n",
    "# Tune the rf model\n",
    "GBPUSD_tuned_knn = tune_model(GBPUSD_knn)\n",
    "\n",
    "# Finalise the model\n",
    "GBPUSD_model = finalize_model(GBPUSD_tuned_knn)\n",
    "\n",
    "# Save the model\n",
    "save_model(GBPUSD_model, 'GBPUSD_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdb4df7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# USDCHF\n",
    "# Below code creates the regresion model, most of it is adapted from the pycaret tutorial\n",
    "\n",
    "        \n",
    "# Set up the regression\n",
    "USDCHF_reg = setup(data = prepared['USDCHF'], target = 'return', session_id=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63caa036",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Select the best model\n",
    "USDCHF_best = compare_models(exclude = ['ransac'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c108b59",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select the best model\n",
    "USDCHF_llar = create_model(\"llar\")\n",
    "\n",
    "# Tune the rf model\n",
    "USDCHF_tuned_llar = tune_model(USDCHF_llar)\n",
    "\n",
    "# Finalise the model\n",
    "USDCHF_model = finalize_model(USDCHF_tuned_llar)\n",
    "\n",
    "# Save the model\n",
    "save_model(USDCHF_model, 'USDCHF_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09a8f302",
   "metadata": {},
   "outputs": [],
   "source": [
    "# USDCAD\n",
    "# Below code creates the regresion model, most of it is adapted from the pycaret tutorial\n",
    "\n",
    "        \n",
    "# Set up the regression\n",
    "USDCAD_reg = setup(data = prepared['USDCAD'], target = 'return', session_id=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c5c11b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Select the best model\n",
    "USDCAD_best = compare_models(exclude = ['ransac'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0aa4eb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select the best model\n",
    "USDCAD_knn = create_model(\"knn\")\n",
    "\n",
    "# Tune the rf model\n",
    "USDCAD_tuned_knn = tune_model(USDCAD_knn)\n",
    "\n",
    "# Finalise the model\n",
    "USDCAD_model = finalize_model(USDCAD_tuned_knn)\n",
    "\n",
    "# Save the model\n",
    "save_model(USDCAD_model, 'USDCAD_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6e75741",
   "metadata": {},
   "outputs": [],
   "source": [
    "# USDHKD\n",
    "# Below code creates the regresion model, most of it is adapted from the pycaret tutorial\n",
    "\n",
    "        \n",
    "# Set up the regression\n",
    "USDHKD_reg = setup(data = prepared['USDHKD'], target = 'return', session_id=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9636adde",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Select the best model\n",
    "USDHKD_best = compare_models(exclude = ['ransac'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22a775ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select the best model\n",
    "USDHKD_llar = create_model(\"llar\")\n",
    "\n",
    "# Tune the rf model\n",
    "USDHKD_tuned_llar = tune_model(USDHKD_llar)\n",
    "\n",
    "# Finalise the model\n",
    "USDHKD_model = finalize_model(USDHKD_tuned_llar)\n",
    "\n",
    "# Save the model\n",
    "save_model(USDHKD_model, 'USDHKD_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02ae9498",
   "metadata": {},
   "outputs": [],
   "source": [
    "# USDAUD\n",
    "# Below code creates the regresion model, most of it is adapted from the pycaret tutorial\n",
    "\n",
    "        \n",
    "# Set up the regression\n",
    "USDAUD_reg = setup(data = prepared['USDAUD'], target = 'return', session_id=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "126a7fc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Select the best model\n",
    "USDAUD_best = compare_models(exclude = ['ransac'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64c2b10f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select the best model\n",
    "USDAUD_br = create_model(\"br\")\n",
    "\n",
    "# Tune the rf model\n",
    "USDAUD_tuned_br = tune_model(USDAUD_br)\n",
    "\n",
    "# Finalise the model\n",
    "USDAUD_model = finalize_model(USDAUD_tuned_br)\n",
    "\n",
    "# Save the model\n",
    "save_model(USDAUD_model, 'USDAUD_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "163c07b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# USDNZD\n",
    "# Below code creates the regresion model, most of it is adapted from the pycaret tutorial\n",
    "\n",
    "        \n",
    "# Set up the regression\n",
    "USDNZD_reg = setup(data = prepared['USDNZD'], target = 'return', session_id=7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5874e5f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Select the best model\n",
    "USDNZD_best = compare_models(exclude = ['ransac'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b02259a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select the best model\n",
    "USDNZD_llar = create_model(\"llar\")\n",
    "\n",
    "# Tune the rf model\n",
    "USDNZD_tuned_llar = tune_model(USDNZD_llar)\n",
    "\n",
    "# Finalise the model\n",
    "USDNZD_model = finalize_model(USDNZD_tuned_llar)\n",
    "\n",
    "# Save the model\n",
    "save_model(USDNZD_model, 'USDNZD_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae43a996",
   "metadata": {},
   "outputs": [],
   "source": [
    "# USDSGD\n",
    "# Below code creates the regresion model, most of it is adapted from the pycaret tutorial\n",
    "\n",
    "        \n",
    "# Set up the regression\n",
    "USDSGD_reg = setup(data = prepared['USDSGD'], target = 'return', session_id=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c7ac894",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Select the best model\n",
    "USDSGD_best = compare_models(exclude = ['ransac'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb6eaa62",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select the best model\n",
    "USDSGD_br = create_model(\"br\")\n",
    "\n",
    "# Tune the rf model\n",
    "USDSGD_tuned_br = tune_model(USDSGD_br)\n",
    "\n",
    "# Finalise the model\n",
    "USDSGD_model = finalize_model(USDSGD_tuned_br)\n",
    "\n",
    "# Save the model\n",
    "save_model(USDSGD_model, 'USDSGD_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "454668f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transformation Pipeline and Model Successfully Loaded\n",
      "Transformation Pipeline and Model Successfully Loaded\n",
      "Transformation Pipeline and Model Successfully Loaded\n",
      "Transformation Pipeline and Model Successfully Loaded\n",
      "Transformation Pipeline and Model Successfully Loaded\n",
      "Transformation Pipeline and Model Successfully Loaded\n",
      "Transformation Pipeline and Model Successfully Loaded\n",
      "Transformation Pipeline and Model Successfully Loaded\n"
     ]
    }
   ],
   "source": [
    "# Load the models ready to be used in the main function\n",
    "loaded_models = {}\n",
    "loaded_models[\"EURUSD\"] = load_model('EURUSD_model')\n",
    "loaded_models[\"GBPUSD\"] = load_model('GBPUSD_model')\n",
    "loaded_models[\"USDCHF\"] = load_model('USDCHF_model')\n",
    "loaded_models[\"USDCAD\"] = load_model('USDCAD_model')\n",
    "loaded_models[\"USDHKD\"] = load_model('USDHKD_model')\n",
    "loaded_models[\"USDAUD\"] = load_model('USDAUD_model')\n",
    "loaded_models[\"USDNZD\"] = load_model('USDNZD_model')\n",
    "loaded_models[\"USDSGD\"] = load_model('USDSGD_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e2271624",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The below are helper functions for the main function\n",
    "# Function slightly modified from polygon sample code to format the date string \n",
    "def ts_to_datetime(ts) -> str:\n",
    "    return datetime.datetime.fromtimestamp(ts / 1000.0).strftime('%Y-%m-%d %H:%M:%S')\n",
    "\n",
    "# Function which clears the raw data tables once we have aggregated the data in a 6 minute interval\n",
    "def reset_raw_data_tables(engine,currency_pairs):\n",
    "    with engine.begin() as conn:\n",
    "        for curr in currency_pairs:\n",
    "            conn.execute(text(\"DROP TABLE \"+curr[0]+curr[1]+\"_raw;\"))\n",
    "            conn.execute(text(\"CREATE TABLE \"+curr[0]+curr[1]+\"_raw(ticktime text, fxrate  numeric, inserttime text);\"))\n",
    "\n",
    "# This creates a table for storing the raw, unaggregated price data for each currency pair in the SQLite database\n",
    "def initialize_raw_data_tables(engine,currency_pairs):\n",
    "    with engine.begin() as conn:\n",
    "        for curr in currency_pairs:\n",
    "            conn.execute(text(\"CREATE TABLE \"+curr[0]+curr[1]+\"_raw(ticktime text, fxrate  numeric, inserttime text);\"))\n",
    "\n",
    "# This creates a table for storing the (6 min interval) aggregated price data for each currency pair in the SQLite database            \n",
    "def initialize_aggregated_tables(engine,currency_pairs):\n",
    "    with engine.begin() as conn:\n",
    "        for curr in currency_pairs:\n",
    "            conn.execute(text(\"CREATE TABLE \"+curr[0]+curr[1]+\"_agg(inserttime text, avgfxrate  numeric, stdfxrate numeric);\"))\n",
    "\n",
    "# Create a table for storing data required for hmwk2 + 3\n",
    "def intialize_ts_tables(engine,currency_pairs):\n",
    "    with engine.begin() as conn:\n",
    "        for curr in currency_pairs:\n",
    "            conn.execute(text(\"CREATE TABLE \"+curr[0]+curr[1]+\"_ts(inserttime text, period text, maximum numeric, minimum numeric, mean numeric, volatility numeric, fd numeric, return numeric);\"))\n",
    "\n",
    "# Create a table for storing the results from the stop loss strategy\n",
    "def intialize_results_tables(engine,currency_pairs):\n",
    "    with engine.begin() as conn:\n",
    "        for curr in currency_pairs:\n",
    "            conn.execute(text(\"CREATE TABLE \"+curr[0]+curr[1]+\"_results(inserttime text, period text, position text, balance numeric, profitloss numeric, status text);\"))\n",
    "            \n",
    "# Create a table for storing the predictions from the regression model\n",
    "def intialize_predictions_tables(engine,currency_pairs):\n",
    "    with engine.begin() as conn:\n",
    "        for curr in currency_pairs:\n",
    "            conn.execute(text(\"CREATE TABLE \"+curr[0]+curr[1]+\"_predictions(inserttime text, predictedreturn numeric, actualreturn text numeric, error numeric);\"))\n",
    "            \n",
    "            \n",
    "# This function is called every 6 minutes to aggregate the data, store it in the aggregate table, \n",
    "# and then delete the raw data\n",
    "def aggregate_raw_data_tables(engine,currency_pairs):\n",
    "    with engine.begin() as conn:\n",
    "        for curr in currency_pairs:\n",
    "            result = conn.execute(text(\"SELECT AVG(fxrate) as avg_price, COUNT(fxrate) as tot_count FROM \"+curr[0]+curr[1]+\"_raw;\"))\n",
    "            for row in result:\n",
    "                avg_price = row.avg_price\n",
    "                tot_count = row.tot_count\n",
    "            std_res = conn.execute(text(\"SELECT SUM((fxrate - \"+str(avg_price)+\")*(fxrate - \"+str(avg_price)+\"))/(\"+str(tot_count)+\"-1) as std_price FROM \"+curr[0]+curr[1]+\"_raw;\"))\n",
    "            for row in std_res:\n",
    "                std_price = sqrt(row.std_price)\n",
    "            date_res = conn.execute(text(\"SELECT MAX(ticktime) as last_date FROM \"+curr[0]+curr[1]+\"_raw;\"))\n",
    "            for row in date_res:\n",
    "                last_date = row.last_date\n",
    "            conn.execute(text(\"INSERT INTO \"+curr[0]+curr[1]+\"_agg (inserttime, avgfxrate, stdfxrate) VALUES (:inserttime, :avgfxrate, :stdfxrate);\"),[{\"inserttime\": last_date, \"avgfxrate\": avg_price, \"stdfxrate\": std_price}])\n",
    "            \n",
    "            # This calculates and stores the return values\n",
    "            exec(\"curr[2].append(\"+curr[0]+curr[1]+\"_return(last_date,avg_price))\")\n",
    "            #exec(\"print(\\\"The return for \"+curr[0]+curr[1]+\" is:\"+str(curr[2][-1].hist_return)+\" \\\")\")\n",
    "            \n",
    "            if len(curr[2]) > 5:\n",
    "                try:\n",
    "                    avg_pop_value = curr[2][-6].hist_return\n",
    "                except:\n",
    "                    avg_pop_value = 0\n",
    "                if isnan(avg_pop_value) == True:\n",
    "                    avg_pop_value = 0\n",
    "            else:\n",
    "                avg_pop_value = 0\n",
    "            # Calculate the average return value and print it/store it\n",
    "            curr_avg = curr[2][-1].get_avg(avg_pop_value)\n",
    "            #exec(\"print(\\\"The average return for \"+curr[0]+curr[1]+\" is:\"+str(curr_avg)+\" \\\")\")\n",
    "            \n",
    "            # Now that we have the average return, loop through the last 5 rows in the list to start compiling the \n",
    "            # data needed to calculate the standard deviation\n",
    "            for row in curr[2][-5:]:\n",
    "                row.add_to_running_squared_sum(curr_avg)\n",
    "            \n",
    "            # Calculate the standard dev using the avg\n",
    "            curr_std = curr[2][-1].get_std()\n",
    "            #exec(\"print(\\\"The standard deviation of the return for \"+curr[0]+curr[1]+\" is:\"+str(curr_std)+\" \\\")\")\n",
    "            \n",
    "            # Calculate the average standard dev\n",
    "            if len(curr[2]) > 5:\n",
    "                try:\n",
    "                    pop_value = curr[2][-6].std_return\n",
    "                except:\n",
    "                    pop_value = 0\n",
    "            else:\n",
    "                pop_value = 0\n",
    "            curr_avg_std = curr[2][-1].get_avg_std(pop_value)\n",
    "            #exec(\"print(\\\"The average standard deviation of the return for \"+curr[0]+curr[1]+\" is:\"+str(curr_avg_std)+\" \\\")\")\n",
    "            \n",
    "\n",
    "#                    ----------------- Hmwk 3 -----------------------\n",
    "\n",
    "\n",
    "# This funtion initialises trading by assigning 5 currencies long positions and 5 currencies short positions.\n",
    "# It adds 100 to their balance.\n",
    "\n",
    "def initialise_trading(engine, currency_pairs, dic):\n",
    "    i = 0\n",
    "    for currency in currency_pairs:\n",
    "        # Set the input variables to the API\n",
    "        from_ = currency[0]\n",
    "        to = currency[1]\n",
    "        i +=1\n",
    "        \n",
    "        if (i % 2 != 0):\n",
    "            dic[f'{from_}{to} position'] = 'long'\n",
    "            dic[f'{from_}{to} balance'] = 100\n",
    "            dic[f'{from_}{to} trade_status'] = 'live'\n",
    "            \n",
    "        \n",
    "        if (i % 2 == 0):\n",
    "            dic[f'{from_}{to} position'] = 'short'\n",
    "            dic[f'{from_}{to} balance'] = 100\n",
    "            dic[f'{from_}{to} trade_status'] = 'live'\n",
    "            \n",
    "\n",
    "# This function contains the stop loss strategy as outlined in the assignment \n",
    "            \n",
    "def stop_loss_strategy(engine, currency_pairs, dic, hours_past):\n",
    "    \n",
    "    # This function gets called every hour\n",
    "\n",
    "    # Loop through each currency pair\n",
    "    for currency in currency_pairs:\n",
    "        # Set the input variables to the API\n",
    "        from_ = currency[0]\n",
    "        to = currency[1]\n",
    "        \n",
    "        \n",
    "    \n",
    "    # We can reference the acceptable loss from this logic array. This refactoring saved many lines of copy and pasted code.\n",
    "    # Each element is an acceptable loss, it's index + 1 is its corresponding phase. I.e 0.250 is acceptable in the first hour, 0.100 is acceptable in the second hour.\n",
    "    \n",
    "        logic = [0.250, 0.150, 0.100, 0.050, 0.050, 0.050, 0.050, 0.050, 0.050, 0.050]\n",
    "            \n",
    "               \n",
    "        # If 10 hours have past, exit the trades and compute the profit/loss\n",
    "        if hours_past == 10:\n",
    "            # Exit trades and compute balance, profit or loss\n",
    "            dic[f'{from_}{to} trade_status'] = 'exited'\n",
    "            dic[f'{from_}{to} balance'] = dic[f'{from_}{to} balance'] * (1 - dic[f'{from_}{to} return'])\n",
    "            \n",
    "            if (dic[f'{from_}{to} position'] == 'long'):\n",
    "                dic[f'{from_}{to} profit_loss'] = (dic[f'{from_}{to} balance'] - dic[f'{from_}{to} total_invested'])\n",
    "            \n",
    "            if (dic[f'{from_}{to} position'] == 'short'):\n",
    "                dic[f'{from_}{to} profit_loss'] = -(dic[f'{from_}{to} balance'] - dic[f'{from_}{to} total_invested'])\n",
    "                \n",
    "            \n",
    "                \n",
    "        else:\n",
    "            # Follow the trading logic   \n",
    "            for index, val in enumerate(logic):\n",
    "                #If first period\n",
    "                if hours_past == index+1:\n",
    "                    #If long\n",
    "                    if (dic[f'{from_}{to} position'] == 'long') & (dic[f'{from_}{to} trade_status'] == 'live'):\n",
    "                    \n",
    "                        # If long and loss is larger than accepted loss compute loss and close trade\n",
    "                        if ((dic[f'{from_}{to} return']) < -(logic[index]/100)):\n",
    "                            dic[f'{from_}{to} trade_status'] = 'exited'\n",
    "                            dic[f'{from_}{to} balance'] = dic[f'{from_}{to} balance'] * (1 - dic[f'{from_}{to} return'])\n",
    "                            \n",
    "\n",
    "                        # If long and loss is less than accepted loss, compute profit or loss, add it to the position and add another 100 to the trade \n",
    "                        if ((dic[f'{from_}{to} return']) >= -(logic[index]/100)):\n",
    "                            dic[f'{from_}{to} balance'] = dic[f'{from_}{to} balance'] + (dic[f'{from_}{to} balance'] * dic[f'{from_}{to} return']) + 100\n",
    "                            dic[f'{from_}{to} total_invested'] += 100\n",
    "                        \n",
    "                        dic[f'{from_}{to} profit_loss'] = (dic[f'{from_}{to} balance'] - dic[f'{from_}{to} total_invested'])\n",
    "                        \n",
    "                        \n",
    "                    if (dic[f'{from_}{to} position'] == 'short') & (dic[f'{from_}{to} trade_status'] == 'live'):\n",
    "                         # If short and gain is larger than accepted gain compute loss and close trade\n",
    "                        if ((dic[f'{from_}{to} return']) > (logic[index]/100)):\n",
    "                            dic[f'{from_}{to} trade_status'] = 'exited'\n",
    "                            dic[f'{from_}{to} balance'] = dic[f'{from_}{to} balance'] * (1 - dic[f'{from_}{to} return'])\n",
    "                            \n",
    "                         # If short and gain is less than accepted gain compute profit or loss add it to the position and add another 100 to the trade\n",
    "                        if ((dic[f'{from_}{to} return']) <= (logic[index]/100)):\n",
    "                            dic[f'{from_}{to} balance'] = dic[f'{from_}{to} balance'] + (dic[f'{from_}{to} balance'] * dic[f'{from_}{to} return']) + 100\n",
    "                            dic[f'{from_}{to} total_invested'] += 100\n",
    "\n",
    "                        dic[f'{from_}{to} profit_loss'] = -(dic[f'{from_}{to} balance'] - dic[f'{from_}{to} total_invested'])\n",
    "        \n",
    "        \n",
    "        \n",
    "        # Get the current time and format it\n",
    "        insert_time = datetime.datetime.now().strftime('%Y-%m-%d %H:%M:%S')\n",
    "        \n",
    "        # Write the results into the db\n",
    "        with engine.begin() as conn:\n",
    "            conn.execute(text(\"INSERT INTO \"+from_+to+\"_results(inserttime, period, position, balance, profitloss, status) VALUES (:inserttime, :period, :position, :balance, :profitloss, :status)\"),[{\"inserttime\": insert_time, \"period\": hours_past, \"position\": dic[f'{from_}{to} position'], \"balance\": dic[f'{from_}{to} balance'], \"profitloss\": dic[f'{from_}{to} profit_loss'], \"status\": dic[f'{from_}{to} trade_status']}])\n",
    "                    \n",
    "        \n",
    "        \n",
    "# This main function repeatedly calls the polygon api every 1 seconds for 24 hours \n",
    "# and stores the results.\n",
    "def main(currency_pairs):\n",
    "    # The api key given by the professor\n",
    "    key = \"beBybSi8daPgsTp5yx5cHtHpYcrjp5Jq\"\n",
    "    \n",
    "    # Number of list iterations - each one should last about 1 second\n",
    "    count = 0\n",
    "    agg_count = 0\n",
    "    hour_count = 0\n",
    "    hours_past = 0\n",
    "    \n",
    "    # Create a dictionary of variables that will act as local storage for the various currency paris\n",
    "    dic = {}\n",
    "    \n",
    "    for currency in currency_pairs:\n",
    "        # Set the input variables to the API\n",
    "        from_ = currency[0]\n",
    "        to = currency[1]\n",
    "        \n",
    "        #Initialise the variables that we will need\n",
    "        dic[f'{from_}{to} maximum'] = float('-inf')\n",
    "        dic[f'{from_}{to} minimum'] = float('inf')\n",
    "        dic[f'{from_}{to} prices'] = []\n",
    "        dic[f'{from_}{to} running_total'] = 0\n",
    "        dic[f'{from_}{to} cross_count'] = 0\n",
    "        dic[f'{from_}{to} period'] = 1\n",
    "        dic[f'{from_}{to} keltner_upper_bands'] = []\n",
    "        dic[f'{from_}{to} keltner_lower_bands'] = []\n",
    "        dic[f'{from_}{to} avg_price'] = None\n",
    "        dic[f'{from_}{to} last_price'] = None\n",
    "        dic[f'{from_}{to} upper_count'] = 0\n",
    "        dic[f'{from_}{to} lower_count'] = 0\n",
    "        dic[f'{from_}{to} fd'] = 0\n",
    "        dic[f'{from_}{to} old_mean'] = 0\n",
    "        dic[f'{from_}{to} mean'] = 0\n",
    "        dic[f'{from_}{to} return'] = 0\n",
    "        # variables that will keep track of investments\n",
    "        dic[f'{from_}{to} balance'] = 0       # we will initialise this to 100\n",
    "        dic[f'{from_}{to} profit_loss'] = 0\n",
    "        dic[f'{from_}{to} total_invested'] = 100\n",
    "        dic[f'{from_}{to} number_of_hours'] = 0\n",
    "        dic[f'{from_}{to} trade_status'] = '' # live or exited\n",
    "        dic[f'{from_}{to} position'] = ''     # long or short\n",
    "        dic[f'{from_}{to} predicted'] = 0     # predicted return from the model\n",
    "        dic[f'{from_}{to} error'] = 0         # error from prediction\n",
    "        \n",
    "        \n",
    "    \n",
    "    \n",
    "    \n",
    "    # Create an engine to connect to the database; setting echo to false should stop it from logging in std.out\n",
    "    engine = create_engine(\"sqlite+pysqlite:///sqlite/final.db\", echo=False, future=True)\n",
    "    \n",
    "    \n",
    "   \n",
    "        \n",
    "    # Create the needed tables in the database\n",
    "    initialize_raw_data_tables(engine,currency_pairs)\n",
    "    initialize_aggregated_tables(engine,currency_pairs)\n",
    "    intialize_ts_tables(engine,currency_pairs)\n",
    "    intialize_results_tables(engine,currency_pairs)\n",
    "    intialize_predictions_tables(engine,currency_pairs)\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    # Start trading!\n",
    "    initialise_trading(engine, currency_pairs, dic)\n",
    "    \n",
    "    # Open a RESTClient for making the api calls\n",
    "    with RESTClient(key) as client:\n",
    "        # Loop that runs until the total duration of the program hits 24 hours. \n",
    "        while count < 86400: # 86400 seconds = 24 hours\n",
    "            \n",
    "            \n",
    "            # Make a check to see if 6 minutes has been reached or not\n",
    "            if agg_count == 360:\n",
    "                \n",
    "                \n",
    "                # Aggregate the data and clear the raw data tables\n",
    "                #aggregate_raw_data_tables(engine,currency_pairs)\n",
    "                reset_raw_data_tables(engine,currency_pairs)\n",
    "                agg_count = 0\n",
    "            \n",
    "            \n",
    "            # Every ten hours run the trailing stop strategy (3600 seconds)\n",
    "            if hour_count == 3600:\n",
    "\n",
    "                \n",
    "                # Run the stop loss strategy\n",
    "                stop_loss_strategy(engine, currency_pairs, dic, hours_past)\n",
    "                \n",
    "                 # Increment hours that have past\n",
    "                hours_past += 1\n",
    "\n",
    "                # Reset hour count\n",
    "                hour_count = 0\n",
    "                \n",
    "               \n",
    "\n",
    "            # Only call the api every 1 second, so wait here for 0.75 seconds, because the \n",
    "            # code takes about .15 seconds to run\n",
    "            time.sleep(0.5)\n",
    "            \n",
    "            # Increment the counters\n",
    "            count += 1\n",
    "            agg_count += 1\n",
    "            hour_count += 1\n",
    "\n",
    "            # Loop through each currency pair\n",
    "            for currency in currency_pairs:\n",
    "                # Set the input variables to the API\n",
    "                from_ = currency[0]\n",
    "                to = currency[1]\n",
    "                \n",
    "                if agg_count == 360:\n",
    "            \n",
    "                    # Every six minutes...\n",
    "                    \n",
    "                    # Calculate the mean\n",
    "                    prices_arr = np.array(dic[f'{from_}{to} prices'])\n",
    "                    dic[f'{from_}{to} running_total'] = prices_arr.sum()\n",
    "                    dic[f'{from_}{to} mean'] = dic[f'{from_}{to} running_total'] / len(prices_arr)\n",
    "                    \n",
    "                    # Calculate the return\n",
    "                    if  dic[f'{from_}{to} period'] > 1:\n",
    "                        dic[f'{from_}{to} return'] = (dic[f'{from_}{to} mean'] - dic[f'{from_}{to} old_mean']) / dic[f'{from_}{to} old_mean']\n",
    "                    else:\n",
    "                        dic[f'{from_}{to} return'] = 0\n",
    "                        \n",
    "                        \n",
    "                    # Assign the previous mean to the old_mean\n",
    "                    dic[f'{from_}{to} old_mean'] = dic[f'{from_}{to} mean']\n",
    "\n",
    "                    \n",
    "                    # Reset values\n",
    "                    dic[f'{from_}{to} prices'] = []\n",
    "                    dic[f'{from_}{to} running_total'] = 0\n",
    "    \n",
    "        \n",
    "                    # Write the volatility info to database\n",
    "                \n",
    "                    with engine.begin() as conn:\n",
    "                        conn.execute(text(\"INSERT INTO \"+from_+to+\"_ts(inserttime, period, maximum, minimum, mean, volatility, fd, return) VALUES (:inserttime, :period, :maximum, :minimum, :mean, :volatility, :fd, :return)\"),[{\"inserttime\": insert_time, \"period\": dic[f'{from_}{to} period'], \"maximum\": dic[f'{from_}{to} maximum'], \"minimum\": dic[f'{from_}{to} minimum'], \"mean\": dic[f'{from_}{to} mean'], \"volatility\": dic[f'{from_}{to} vol'], \"fd\": dic[f'{from_}{to} fd'], \"return\": dic[f'{from_}{to} return']}])\n",
    "                    \n",
    "                    \n",
    "                    # Write the prediction info into the db\n",
    "                    \n",
    "                    dic[f'{from_}{to} error'] = dic[f'{from_}{to} return'] - dic[f'{from_}{to} predicted']\n",
    "                    \n",
    "                    \n",
    "                    with engine.begin() as conn:\n",
    "                        conn.execute(text(\"INSERT INTO \"+from_+to+\"_predictions(inserttime, predictedreturn, actualreturn, error) VALUES (:inserttime, :predictedreturn, :actualreturn, :error)\"),[{\"inserttime\": insert_time, \"predictedreturn\": dic[f'{from_}{to} predicted'], \"actualreturn\": dic[f'{from_}{to} return'], \"error\": dic[f'{from_}{to} error'] }])\n",
    "                                       \n",
    "                    \n",
    "                    # Run the prediction for next period\n",
    "                    \n",
    "                    data = {'inserttime': [insert_time], 'maximum': [dic[f'{from_}{to} maximum']], 'minimum': [dic[f'{from_}{to} minimum']],'mean': [dic[f'{from_}{to} mean']], 'volatility': [dic[f'{from_}{to} vol']], 'fd': [dic[f'{from_}{to} fd']], 'return': [dic[f'{from_}{to} return']] }\n",
    "                    df = pd.DataFrame(data=data)\n",
    "                    predictions[f'{from_}{to}'] = predict_model(loaded_models[f'{from_}{to}'], data = df)\n",
    "\n",
    "                    # Save the prediction to the dictionary                    \n",
    "                    dic[f'{from_}{to} predicted'] = predictions[f'{from_}{to}'].loc[0]['Label'] / 100000\n",
    "                    \n",
    "                    \n",
    "                    \n",
    "                    # Reset the currency specific variables\n",
    "                    dic[f'{from_}{to} maximum'] = float('-inf')\n",
    "                    dic[f'{from_}{to} minimum'] = float('inf')\n",
    "                    dic[f'{from_}{to} cross_count'] = 0 \n",
    "                    dic[f'{from_}{to} period'] +=1\n",
    "\n",
    "                    dic[f'{from_}{to} keltner_upper_bands'] = []\n",
    "                    dic[f'{from_}{to} keltner_lower_bands'] = []\n",
    "                    dic[f'{from_}{to} upper_count'] = 0\n",
    "                    dic[f'{from_}{to} lower_count'] = 0\n",
    "\n",
    "                    \n",
    "\n",
    "                    # If the first period has passed, calculate the keltner bands\n",
    "                    if dic[f'{from_}{to} period'] > 1:\n",
    "\n",
    "                    # Create 100 upper Keltner bands\n",
    "                        for num in range(100):\n",
    "                            calc = dic[f'{from_}{to} mean'] + num*0.025*dic[f'{from_}{to} vol']\n",
    "                            dic[f'{from_}{to} keltner_upper_bands'].append(calc)\n",
    "                            \n",
    "                    # Create 100 lower Keltner bands\n",
    "                        for num in range(100):\n",
    "                            calc = dic[f'{from_}{to} mean'] - num*0.025*dic[f'{from_}{to} vol']\n",
    "                            dic[f'{from_}{to} keltner_lower_bands'].append(calc)\n",
    "                        \n",
    "                \n",
    "\n",
    "                # Call the API with the required parameters\n",
    "                try:\n",
    "                    resp = client.forex_currencies_real_time_currency_conversion(from_, to, amount=100, precision=2)\n",
    "                except:\n",
    "                    continue\n",
    "\n",
    "                # This gets the Last Trade object defined in the API Resource\n",
    "                last_trade = resp.last\n",
    "\n",
    "                # Format the timestamp from the result\n",
    "                dt = ts_to_datetime(last_trade[\"timestamp\"])\n",
    "\n",
    "                # Get the current time and format it\n",
    "                insert_time = datetime.datetime.now().strftime('%Y-%m-%d %H:%M:%S')\n",
    "                \n",
    "                # Assign the old average price to the last price\n",
    "                dic[f'{from_}{to} last_price'] = dic[f'{from_}{to} avg_price']\n",
    "                \n",
    "                \n",
    "                # Calculate the new average price by taking the average of the bid and ask prices\n",
    "                avg_price = (last_trade['bid'] + last_trade['ask'])/2\n",
    "                dic[f'{from_}{to} avg_price'] = (last_trade['bid'] + last_trade['ask'])/2\n",
    "                \n",
    "                # Calculate the max price in the past six minutes\n",
    "                if dic[f'{from_}{to} avg_price'] > dic[f'{from_}{to} maximum']:\n",
    "                    dic[f'{from_}{to} maximum'] = dic[f'{from_}{to} avg_price']\n",
    "                            \n",
    "                # Calculate the min price in the last six minutes\n",
    "                if dic[f'{from_}{to} avg_price'] < dic[f'{from_}{to} minimum']:\n",
    "                    dic[f'{from_}{to} minimum'] = dic[f'{from_}{to} avg_price']\n",
    "                \n",
    "                # Calculate the volatility over the last six minutes, ensure that we divide by the average price in order to standardise the value\n",
    "                dic[f'{from_}{to} vol'] = (dic[f'{from_}{to} maximum'] - dic[f'{from_}{to} minimum']) / dic[f'{from_}{to} avg_price']\n",
    "                \n",
    "                # Replace the vol with a class (1,2,3)\n",
    "                vol_arr = vol_data[f'{from_}{to}'].to_numpy().tolist()\n",
    "                vol_arr.append(dic[f'{from_}{to} vol'])\n",
    "                vol_r = vol_arr.index(dic[f'{from_}{to} vol'])\n",
    "                if vol_r <= 32:\n",
    "                    dic[f'{from_}{to} vol'] = 1\n",
    "                    \n",
    "                if (vol_r > 32) &  vol_r <= 66:\n",
    "                    dic[f'{from_}{to} vol'] = 2\n",
    "                \n",
    "                if (vol_r > 66):\n",
    "                    dic[f'{from_}{to} vol'] = 3\n",
    "                    \n",
    "                \n",
    "                # Calculate the fractal dimension\n",
    "                # For each new price we want to know how many bands have been crossed. \n",
    "        \n",
    "                upper = np.array(dic[f'{from_}{to} keltner_upper_bands'])\n",
    "                lower = np.array(dic[f'{from_}{to} keltner_lower_bands'])\n",
    "                \n",
    "                # How many numbers in the keltner band are greater than the old price and less than the new price\n",
    "                if dic[f'{from_}{to} last_price'] is not None:\n",
    "                    dic[f'{from_}{to} upper_count'] = ((dic[f'{from_}{to} last_price'] < upper) & (upper < dic[f'{from_}{to} avg_price'])).sum()\n",
    "\n",
    "                # How many numbers in the keltner band are less than the old price and greater than the new price\n",
    "                if dic[f'{from_}{to} last_price'] is not None:\n",
    "                    dic[f'{from_}{to} lower_count'] = ((dic[f'{from_}{to} last_price'] > lower) & (lower > dic[f'{from_}{to} avg_price'])).sum()\n",
    "\n",
    "                # Add the above counts from upper and lower bands together\n",
    "                dic[f'{from_}{to} cross'] = dic[f'{from_}{to} upper_count'] + dic[f'{from_}{to} lower_count']\n",
    "                \n",
    "                # Add the total to the running total of crosses over the six minute period\n",
    "                dic[f'{from_}{to} cross_count'] = dic[f'{from_}{to} cross_count'] +  dic[f'{from_}{to} cross']\n",
    "                \n",
    "                # Divide the cross_count by the volatility in order to calculte the fractal dimenstion\n",
    "                if  (dic[f'{from_}{to} maximum'] - dic[f'{from_}{to} minimum']) != 0:\n",
    "                     dic[f'{from_}{to} fd'] = dic[f'{from_}{to} cross_count'] /  (dic[f'{from_}{to} maximum'] - dic[f'{from_}{to} minimum'])\n",
    "                \n",
    "                # Replace the fd with a class (1,2,3)\n",
    "                fd_arr = fd_data[f'{from_}{to}'].to_numpy().tolist()\n",
    "                fd_arr.append(dic[f'{from_}{to} fd'])\n",
    "                fd_r = fd_arr.index(dic[f'{from_}{to} fd'])\n",
    "                if fd_r <= 32:\n",
    "                    dic[f'{from_}{to} fd'] = 1\n",
    "                    \n",
    "                if (fd_r > 32) &  fd_r <= 66:\n",
    "                    dic[f'{from_}{to} fd'] = 2\n",
    "                \n",
    "                if (fd_r > 66):\n",
    "                    dic[f'{from_}{to} fd'] = 3\n",
    "                \n",
    "                # Keep track of prices over last 6 minutes\n",
    "                (dic[f'{from_}{to} prices']).append(dic[f'{from_}{to} avg_price'])\n",
    "                \n",
    "                \n",
    "                # Write the data to the SQLite database, raw data tables\n",
    "                with engine.begin() as conn:\n",
    "                    conn.execute(text(\"INSERT INTO \"+from_+to+\"_raw(ticktime, fxrate, inserttime) VALUES (:ticktime, :fxrate, :inserttime)\"),[{\"ticktime\": dt, \"fxrate\": avg_price, \"inserttime\": insert_time}])\n",
    "                \n",
    "                \n",
    "                    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3a4e3472",
   "metadata": {},
   "outputs": [
    {
     "ename": "OperationalError",
     "evalue": "(sqlite3.OperationalError) table EURUSD_raw already exists\n[SQL: CREATE TABLE EURUSD_raw(ticktime text, fxrate  numeric, inserttime text);]\n(Background on this error at: https://sqlalche.me/e/14/e3q8)",
     "output_type": "error",
     "traceback": [
      "Traceback \u001b[0;36m(most recent call last)\u001b[0m:\n",
      "  File \u001b[1;32m\"/Users/marcusrapacioli/opt/anaconda3/envs/pycaret/lib/python3.8/site-packages/sqlalchemy/engine/base.py\"\u001b[0m, line \u001b[1;32m1900\u001b[0m, in \u001b[1;35m_execute_context\u001b[0m\n    self.dialect.do_execute(\n",
      "\u001b[0;36m  File \u001b[0;32m\"/Users/marcusrapacioli/opt/anaconda3/envs/pycaret/lib/python3.8/site-packages/sqlalchemy/engine/default.py\"\u001b[0;36m, line \u001b[0;32m736\u001b[0;36m, in \u001b[0;35mdo_execute\u001b[0;36m\u001b[0m\n\u001b[0;31m    cursor.execute(statement, parameters)\u001b[0m\n",
      "\u001b[0;31mOperationalError\u001b[0m\u001b[0;31m:\u001b[0m table EURUSD_raw already exists\n",
      "\nThe above exception was the direct cause of the following exception:\n",
      "Traceback \u001b[0;36m(most recent call last)\u001b[0m:\n",
      "  File \u001b[1;32m\"/var/folders/56/58bs7fss6hbc3wf9589_7mww0000gn/T/ipykernel_35639/786041253.py\"\u001b[0m, line \u001b[1;32m2\u001b[0m, in \u001b[1;35m<cell line: 2>\u001b[0m\n    main(currency_pairs)\n",
      "  File \u001b[1;32m\"/var/folders/56/58bs7fss6hbc3wf9589_7mww0000gn/T/ipykernel_35639/81402068.py\"\u001b[0m, line \u001b[1;32m263\u001b[0m, in \u001b[1;35mmain\u001b[0m\n    initialize_raw_data_tables(engine,currency_pairs)\n",
      "  File \u001b[1;32m\"/var/folders/56/58bs7fss6hbc3wf9589_7mww0000gn/T/ipykernel_35639/81402068.py\"\u001b[0m, line \u001b[1;32m17\u001b[0m, in \u001b[1;35minitialize_raw_data_tables\u001b[0m\n    conn.execute(text(\"CREATE TABLE \"+curr[0]+curr[1]+\"_raw(ticktime text, fxrate  numeric, inserttime text);\"))\n",
      "  File \u001b[1;32m\"/Users/marcusrapacioli/opt/anaconda3/envs/pycaret/lib/python3.8/site-packages/sqlalchemy/future/engine.py\"\u001b[0m, line \u001b[1;32m280\u001b[0m, in \u001b[1;35mexecute\u001b[0m\n    return self._execute_20(\n",
      "  File \u001b[1;32m\"/Users/marcusrapacioli/opt/anaconda3/envs/pycaret/lib/python3.8/site-packages/sqlalchemy/engine/base.py\"\u001b[0m, line \u001b[1;32m1705\u001b[0m, in \u001b[1;35m_execute_20\u001b[0m\n    return meth(self, args_10style, kwargs_10style, execution_options)\n",
      "  File \u001b[1;32m\"/Users/marcusrapacioli/opt/anaconda3/envs/pycaret/lib/python3.8/site-packages/sqlalchemy/sql/elements.py\"\u001b[0m, line \u001b[1;32m334\u001b[0m, in \u001b[1;35m_execute_on_connection\u001b[0m\n    return connection._execute_clauseelement(\n",
      "  File \u001b[1;32m\"/Users/marcusrapacioli/opt/anaconda3/envs/pycaret/lib/python3.8/site-packages/sqlalchemy/engine/base.py\"\u001b[0m, line \u001b[1;32m1572\u001b[0m, in \u001b[1;35m_execute_clauseelement\u001b[0m\n    ret = self._execute_context(\n",
      "  File \u001b[1;32m\"/Users/marcusrapacioli/opt/anaconda3/envs/pycaret/lib/python3.8/site-packages/sqlalchemy/engine/base.py\"\u001b[0m, line \u001b[1;32m1943\u001b[0m, in \u001b[1;35m_execute_context\u001b[0m\n    self._handle_dbapi_exception(\n",
      "  File \u001b[1;32m\"/Users/marcusrapacioli/opt/anaconda3/envs/pycaret/lib/python3.8/site-packages/sqlalchemy/engine/base.py\"\u001b[0m, line \u001b[1;32m2124\u001b[0m, in \u001b[1;35m_handle_dbapi_exception\u001b[0m\n    util.raise_(\n",
      "  File \u001b[1;32m\"/Users/marcusrapacioli/opt/anaconda3/envs/pycaret/lib/python3.8/site-packages/sqlalchemy/util/compat.py\"\u001b[0m, line \u001b[1;32m210\u001b[0m, in \u001b[1;35mraise_\u001b[0m\n    raise exception\n",
      "  File \u001b[1;32m\"/Users/marcusrapacioli/opt/anaconda3/envs/pycaret/lib/python3.8/site-packages/sqlalchemy/engine/base.py\"\u001b[0m, line \u001b[1;32m1900\u001b[0m, in \u001b[1;35m_execute_context\u001b[0m\n    self.dialect.do_execute(\n",
      "\u001b[0;36m  File \u001b[0;32m\"/Users/marcusrapacioli/opt/anaconda3/envs/pycaret/lib/python3.8/site-packages/sqlalchemy/engine/default.py\"\u001b[0;36m, line \u001b[0;32m736\u001b[0;36m, in \u001b[0;35mdo_execute\u001b[0;36m\u001b[0m\n\u001b[0;31m    cursor.execute(statement, parameters)\u001b[0m\n",
      "\u001b[0;31mOperationalError\u001b[0m\u001b[0;31m:\u001b[0m (sqlite3.OperationalError) table EURUSD_raw already exists\n[SQL: CREATE TABLE EURUSD_raw(ticktime text, fxrate  numeric, inserttime text);]\n(Background on this error at: https://sqlalche.me/e/14/e3q8)\n"
     ]
    }
   ],
   "source": [
    "# Run the main data collection loop\n",
    "main(currency_pairs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54b9efe5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (Spyder)",
   "language": "python3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
